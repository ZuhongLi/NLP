'''
@author:Lee
@file:jiebaDemo.py
@Time: 2019/5/5 10:41
@Description:使用jieba分词实例
'''
from __future__ import print_function,unicode_literals
import jieba
# jieba.load_userdict('./userdict.txt')
# seg_list = jieba.cut('我来到甘肃兰州大学',cut_all=True)
# print('Full Model:'+'/'.join(seg_list))  # 全模式
#
# seg_list = jieba.cut('我来到甘肃兰州大学',cut_all=False)
# print('Default Model:'+'/'.join(seg_list))  # 精确模式
#
# seg_list = jieba.cut('我来到甘肃兰州大学',cut_all=False)
# print(','.join(seg_list))
#
# seg_list = jieba.cut_for_search('我来到了兰州大学，日后打算去南方')  #  搜索引擎模式
# print(','.join(seg_list))


#encoding=utf-8

import sys
sys.path.append('../')
jieba.load_userdict('userdict.txt')
import jieba.posseg as psg
jieba.add_word('凯特琳')
jieba.add_word('台中')
jieba.add_word('石墨烯')
jieba.add_word('创新办',tag='i')
jieba.del_word('自定义库')
test_sent = ('李磊和王二狗是创新办主任也是云计算方面的专家；什么是八一双鹿\n'
             '例如我输入一个带“风花雪月”的标题，在自定义库中也会增加此词为N类\n'
             '[台中]正确应该不会被切开。mac上可分出[石墨烯]，此时又可分出凯特琳了\n')
words = jieba.cut(test_sent)
print('/'.join(words))

print('='*40)
result = psg.cut(test_sent)
for w in result:
    print(w.word,'/',w.flag,',',end=' ')
print('\n'+'='*40)


terms = jieba.cut('easy_install is great')
print('/'.join(terms))

terms = jieba.cut('python 的正则表达式是好用的')
print('/'.join(terms))

print('='*40)

test_list = [('今天天气不错',('今天','天气')),
             ('我们中出了一个叛徒',('中','出'))]
for sent,seg in test_list:
    print('/'.join(jieba.cut(sent,HMM=False)))
    word = ''.join(seg)
    print('%s Before: %s,After: %s'%(word,jieba.get_FREQ(word),jieba.suggest_freq(seg,True)))

    print('/'.join(jieba.cut(sent,HMM=False)))
    print('-'*40)


jieba.add_word('自然语言处理',tag='n')
words = psg.cut('自然语言处理是计算机科学、人工智能、语言学关注计算机和人类语言之间的相互作用的领域')
for word, flag in words:
    print('%s %s '%(word,flag))
